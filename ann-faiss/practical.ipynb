{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Nearest Neighbor (ANN) Methods\n",
    "\n",
    "In this practical, we would like to compare exhaustive search to ANN methods\n",
    "\n",
    "  * Exhaustive Search, Product Quantization (PQ) and Vector Quantization\n",
    "\n",
    "  * Will only count the time/memory of retrieval (as set up times, e.g. for indexing, only have to be done once)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset and utility functions\n",
    "\n",
    "* Download the SIFT1M dataset.\n",
    "* Initialise some useful functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import time\n",
    "import faiss\n",
    "import shutil\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from contextlib import closing\n",
    "import urllib.request as request\n",
    "\n",
    "# first we download the Sift1M dataset\n",
    "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
    "    with open('sift.tar.gz', 'wb') as f:\n",
    "        shutil.copyfileobj(r, f)\n",
    "\n",
    "# the download leaves us with a tar.gz file, we unzip it\n",
    "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
    "tar.extractall()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# function: read the fvecs file format of Sift1M dataset\n",
    "def read_fvecs(fp):\n",
    "    a = np.fromfile(fp, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# function: compute memory usage \n",
    "def get_memory(index, inMB = True):\n",
    "  faiss.write_index(index, './temp.index')\n",
    "  filesize = os.path.getsize('./temp.index')\n",
    "  os.remove('./temp.index')\n",
    "  if inMB: return filesize / (1024*1024)\n",
    "  else: return filesize\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start benchmarking\n",
    "\n",
    "This bring us to the three metrics of interest:\n",
    "\n",
    "- **Speed**. How long does it take to find the 10 (or some other number) most similar vectors to the query? Hopefully less time than the brute-force algorithm needs; otherwise, what’s the point of indexing?\n",
    "\n",
    "- **Memory usage**. How much RAM does the method require? More or less than the original vectors? Faiss supports searching only from RAM, as disk databases are orders of magnitude slower. Yes, even with SSDs.\n",
    "\n",
    "- **Accuracy**. How well does the returned list of results match the brute-force search results? Accuracy can be evaluated by counting the number of queries for which the true nearest neighbor is returned first in the result list (a measure called 1-recall@1), or by measuring the average fraction of 10 nearest neighbors that are returned in the 10 first results (the “10-intersection” measure).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exhaustive Search NN\n",
    "\n",
    "def ESNN(xq, xb, k):\n",
    "    D = xb.shape[1] # size of the vectors\n",
    "    Nindex = faiss.IndexFlatL2(D) # build the index\n",
    "    Nindex.add(xb)                # add vectors to the index, no processing is applied to the vectors\n",
    "    start = time.time()\n",
    "    Ndist, Ni = Nindex.search(xq, k)  # actual search, Ndist: distance, Ni: the index of the NN\n",
    "    end = time.time()\n",
    "    NMem = get_memory(Nindex)\n",
    "    return [end-start, NMem, Ndist, Ni]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Index Product Quantization\n",
    "\n",
    "def PQNN(xq, xb, k, m, nbits):\n",
    "  # m: number of subvectors you'd like to split\n",
    "  # nbits: number of bits per subquantizer, k_ = 2**nbits, i.e. number of centroids per sub-space\n",
    "  D = xb.shape[1] # size of the vectors\n",
    "  assert D % m == 0  # make sure it's divisible\n",
    "\n",
    "  PQindex = faiss.IndexPQ(D, m, nbits) # build the index\n",
    "  PQindex.train(xb)  # PQ training can take some time when using large nbits\n",
    "  PQindex.add(xb)\n",
    "\n",
    "  start = time.time()\n",
    "  PQdist, PQi = PQindex.search(xq, k)\n",
    "  end = time.time()\n",
    "  PQMem = get_memory(PQindex)\n",
    "  return [end-start, PQMem, PQdist, PQi]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Index IVFPQ\n",
    "# To speed up our search time we can add another step, using an IVF index.\n",
    "\n",
    "def IVFPQNN(xq, xb, k=5, nlist=2048, nbits=8, nprobe=2):\n",
    "  # nlist: how many Voronoi cells\n",
    "  # nbits: when using IVF+PQ, can use 8, higher nbits values are not supported\n",
    "  # nprobe: number of centroids for searching\n",
    "\n",
    "  D = xb.shape[1] # size of the vectors\n",
    "  quantizer = faiss.IndexFlatL2(D)\n",
    "\n",
    "  IVFPQindex = faiss.IndexIVFPQ(quantizer, D, nlist, m, nbits)\n",
    "  IVFPQindex.train(xb)\n",
    "  IVFPQindex.add(xb)\n",
    "  IVFPQindex.nprobe = nprobe \n",
    "\n",
    "  start = time.time()\n",
    "  IVFPQdist, IVFPQi = IVFPQindex.search(xq, k)\n",
    "  end = time.time()\n",
    "  IVFPQMem = get_memory(IVFPQindex)\n",
    "  return [end-start, IVFPQMem, IVFPQdist, IVFPQi]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def compareRecall(gt, pred):\n",
    "  tp = 0\n",
    "  for c, i in enumerate(gt): tp += int(i[0] in pred[c])\n",
    "  recall = tp / gt.shape[0]\n",
    "  return recall"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# data we will search through \n",
    "xb = read_fvecs('./sift/sift_base.fvecs')  # 1M samples\n",
    "# also get some query vectors to search with\n",
    "xq = read_fvecs('./sift/sift_query.fvecs')\n",
    "# take just a hundred query (there are many in sift_query)\n",
    "xq = xq[:100]\n",
    "print(xb.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Exhaustive Search NN\n",
    "# for each query vector in xq, it looks for the k=5 nearest neighbors in the xb. \n",
    "\n",
    "ESpred = ESNN(xq=xq, xb=xb, k=5)\n",
    "[EStime, ESmem, ESdist, ESi] = ESpred # Ndist: Euclidean distance, Ni: refers to the indices of the 5 NN.\n",
    "numQ = xq.shape[0]\n",
    "print('Exhaustive Search, searching {} vectors, time: {:.3f}s, memory: {:.2f}MB, recall: {:.2f}'.format(numQ, EStime, ESmem, 1.0))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "xb.shape[0] * 2*2/8/(1024*1024)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "xb.shape[0] * 2/(1024*1024)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "1.91 - 0.476837158203125"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "1.92 - 1.433162841796875"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Product Quantization NN\n",
    "# m: number of subvectors you'd like to split\n",
    "# nbits: number of bits per subquantizer\n",
    "\n",
    "for m in [2, 4, 8, 16]:\n",
    "  for nbits in [2, 4, 6, 8]:\n",
    "    PQpred = PQNN(xq=xq, xb=xb, k=5, m=m, nbits=nbits)\n",
    "    [PQtime, PQmem, PQdist, PQi] = PQpred\n",
    "    numQ = xq.shape[0]\n",
    "    recall = compareRecall(gt=ESi, pred=PQi)\n",
    "    print('PQ NN, searching {} vectors, m: {}, nbits: {}, time: {:.3f}s, memory: {:.2f}MB, recall: {:.2f}'.format(numQ, m, nbits, PQtime, PQmem, recall))\n",
    "  print('-'*60)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PQpred = PQNN(xq=xq, xb=xb, k=5, m=4, nbits=16)\n",
    "[PQtime, PQmem, PQdist, PQi] = PQpred\n",
    "numQ = xq.shape[0]\n",
    "recall = compareRecall(gt=ESi, pred=PQi)\n",
    "print('PQ NN, searching {} vectors, m: {}, nbits: {}, time: {:.3f}s, memory: {:.2f}MB, recall: {:.2f}'.format(numQ, m, nbits, PQtime, PQmem, recall))"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Product Quantization NN\n",
    "# m: number of subvectors you'd like to split\n",
    "# nbits: number of bits per subquantizer\n",
    "\n",
    "for m in [2, 4, 8, 16]:\n",
    "  for nbits in [2, 4, 6, 8]:\n",
    "    PQpred = PQNN(xq=xq, xb=xb, k=5, m=m, nbits=nbits)\n",
    "    [PQtime, PQmem, PQdist, PQi] = PQpred\n",
    "    numQ = xq.shape[0]\n",
    "    recall = compareRecall(gt=ESi, pred=PQi)\n",
    "    print('PQ NN, searching {} vectors, m: {}, nbits: {}, time: {:.3f}s, memory: {:.2f}MB, recall: {:.2f}'.format(numQ, m, nbits, PQtime, PQmem, recall))\n",
    "  print('-'*60)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Product Quantization NN\n",
    "# m: number of subvectors you'd like to split\n",
    "# nbits: number of bits per subquantizer\n",
    "\n",
    "for m in [2, 4, 8, 16]:\n",
    "  for nbits in [2, 4, 6, 8]:\n",
    "    PQpred = PQNN(xq=xq, xb=xb, k=5, m=m, nbits=nbits)\n",
    "    [PQtime, PQmem, PQdist, PQi] = PQpred\n",
    "    numQ = xq.shape[0]\n",
    "    recall = compareRecall(gt=ESi, pred=PQi)\n",
    "    print('PQ NN, searching {} vectors, m: {}, nbits: {}, time: {:.3f}s, memory: {:.2f}MB, recall: {:.2f}'.format(numQ, m, nbits, PQtime, PQmem, recall))\n",
    "  print('-'*60)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Question: How can you further increase the recall ?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# IVFPQ NN\n",
    "# nlist:  # how many Voronoi cells\n",
    "# nbits: # when using IVF+PQ, higher nbits values are not supported\n",
    "# nprobe: # of cells you'd like to search.\n",
    "nbits = 8\n",
    "nlist = 2048\n",
    "nprobe = 2\n",
    "IVFPQpred = IVFPQNN(xq=xq, xb=xb, k=5, nlist=nlist, nbits=nbits, nprobe=nprobe)\n",
    "numQ = xq.shape[0]\n",
    "[IVFPQtime, IVFPQmem, IVFPQdist, IVFPQi] = IVFPQpred\n",
    "recall = compareRecall(gt=ESi, pred=IVFPQi)\n",
    "print('IVFPQ NN, searching {} vectors, nlist: {}, nbits: {}, nprobe: {}, time: {:.3f}s, memory: {:.2f}MB, recall: {:.2f}'.format(numQ, nlist, nbits, nprobe, IVFPQtime, IVFPQmem, recall))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quetion: try to increase nprobe, what happens ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More detailed benchmark can be found at http://ann-benchmarks.com/faiss-ivf.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
